# -*- coding: utf-8 -*-
"""201021_02_DeepLearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11WxxR-uPwzWn7IXpS9bnCW0izVcbl28c
"""

import tensorflow as tf
import keras
import numpy as np
import sys
import pandas as pd

### 머신러닝 - 딥러닝

from keras.models import Sequential
from keras.layers import Dense

"""### 변수 3개 이상 사용"""

train=pd.read_csv('train.csv', parse_dates=['datetime'])
test=pd.read_csv('test.csv', parse_dates=['datetime'])
sub=pd.read_csv('sampleSubmission.csv')

input_col = ['windspeed', 'atemp','humidity','weather']   # 온도, 체감온도
X = train[input_col]   # 학습 데이터의 입력
Y = train['count']     # 학습 데이터의 출력

# 새로운 데이터
X_test = test[input_col]

model=Sequential()

# input_dim : 입력층의 노드수
# 30 : 입력층 다음의 노드 수
model.add(Dense(30,input_dim=4, activation='relu'))
model.add(Dense(15,'relu'))
model.add(Dense(15,'relu'))
model.add(Dense(1))

# 오차 함수, 최적화 함수
model.compile(loss='mean_squared_error', optimizer='rmsprop')

# epochs = 데이터가 10000개가 있을 때 몇 번 훈련시킬 건지
# batch_size = 한 번 훈련시킬 때, 데이터를 몇개씩 할건지
model.fit(X,Y,epochs=20,batch_size=10)

pred=model.predict(X_test)

sub=pd.read_csv('sampleSubmission.csv')
sub['count']=pred;

sub.loc[sub['count']<0, 'count']=0

#처음 만드는 제출용 csv파일, 행 번호 제거
sub.to_csv('NNsub_4_01.csv',index=False)

"""### 두번째 데이터 셋 - MNIST"""

# 십진 숫자를 0,1의 구성으로

from keras.utils import np_utils 

from keras.datasets import mnist

(x_train, y_train),(x_test,y_test)=mnist.load_data()

import matplotlib.pyplot as plt

figure,axes = plt.subplots(nrows=3, ncols=5)  # 3행 5열의 구조 
figure.set_size_inches(18,12)  # 전체 크기

plt.gray()
print("label={}".format(y_train[0:15]))   # x데이터 0~14개 가져오기

col = 0
for row in range(0,3):
    col = row * 5
    axes[row][0].imshow(x_train[col])  # 0,5,10의 값을 갖는 위치 값 이미지 표시
    axes[row][1].imshow(x_train[col+1])# 1,6,11의 값을 갖는 위치 값 이미지 표시
    axes[row][2].imshow(x_train[col+2])# 2,7,12의 값을 갖는 위치 값 이미지 표시
    axes[row][3].imshow(x_train[col+3])# 3,8,13의 값을 갖는 위치 값 이미지 표시
    axes[row][4].imshow(x_train[col+4])# 4,9,114의 값을 갖는 위치 값 이미지 표시

# 이미지 한 장
print(x_train[0].shape)

"""### 데이터 전처리 (차원 맞춰주기 위함)
* x_train, x_test (이미지 갯수, 28, 28) -> (60000, 784)
* y_train, y_test (0~9) -> 0,1의 벡터로 변경
"""

# 변경 전 상태
print(x_train.shape, x_test.shape)
print(y_train.shape, y_train.shape)

X_train=x_train.reshape(60000, 28*28)
X_test=x_test.reshape(10000, 28*28)

Y_train=np_utils.to_categorical(y_train)
Y_test = np_utils.to_categorical(y_test)

# 변경 후 상태
print(X_train.shape, X_test.shape)
print(Y_train.shape, Y_train.shape)

model = Sequential()
model.add( Dense(8, input_dim=28*28, activation='relu') )
model.add( Dense(8, activation="relu") )
model.add( Dense(10, activation='softmax') )

model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])

### 모델 훈련
hist = model.fit(X_train, Y_train, epochs=10, batch_size=32)

model.evaluate(X_test, Y_test)

"""### 어떻게 모델 개선이 가능한가"""

X_train=x_train.reshape(60000, 28*28).astype('float32')/255.0
X_test=x_test.reshape(10000, 28*28).astype('float32')/255.0

Y_train=np_utils.to_categorical(y_train)
Y_test = np_utils.to_categorical(y_test)

model = Sequential()
model.add( Dense(8, input_dim=28*28, activation='relu') )
model.add( Dense(8, activation="relu") )
model.add( Dense(10, activation='softmax') )

model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])

### 모델 훈련
hist = model.fit(X_train, Y_train, epochs=10, batch_size=32)

model.evaluate(X_test, Y_test)

